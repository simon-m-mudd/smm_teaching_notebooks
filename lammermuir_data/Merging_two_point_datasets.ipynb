{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbddd3b4",
   "metadata": {},
   "source": [
    "# Finding nearest points and mapping values from those points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c1783",
   "metadata": {},
   "source": [
    "*Written by Simon M. Mudd at the University of Edinburgh, last update 10/11/2021*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1b2ac",
   "metadata": {},
   "source": [
    "This short tutorial is for the case when you have two sets of point data and want to map values of one of the point datasets to the nearest point on the other dataset.\n",
    "\n",
    "The example here will be a point dataset that represents a channel, and that includes elevation, drainage area, and other values, and a second dataset that represents measurements of channel width. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2f945b",
   "metadata": {},
   "source": [
    "## Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa77168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74334858",
   "metadata": {},
   "source": [
    "## Load the necessary datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efd7ce",
   "metadata": {},
   "source": [
    "We have two datasets. One is the channel data and the other is data about channel width. This second dataset could be any set of points. \n",
    "\n",
    "We will, in the next step, merge these datasets based on the nearest neighbour to one of the set of points (i.e., mapping channel data to the nearest channel width point). \n",
    "\n",
    "For this to work, **the two datasets must be in the same coordinate reference system**.\n",
    "\n",
    "In the example below, we use `.crs` to define the coordinate reference system. We can do this because we know that one of the datasets is in `EPSG:4326` because it has latitude and longitude data, and the other one is in `EPSG:27700`, which is the British National Grid, because it is mean to mimic data collected by students in the field using GPS that have the British National Grid as default. \n",
    "\n",
    "We then convert the data from British National Grid to `EPSG:4326` using the function `.to_crs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034f1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the channel data\n",
    "dfA = pd.read_csv(\"el_study_chi_data_map.csv\")\n",
    "# Convert to a geopandas dataframe\n",
    "gdfA = gpd.GeoDataFrame(\n",
    "    dfA, geometry=gpd.points_from_xy(dfA.longitude, dfA.latitude))\n",
    "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
    "# All major geographic projection and transformation system have this code. \n",
    "gdfA.crs = \"EPSG:4326\" \n",
    "\n",
    "\n",
    "# Load the width data\n",
    "dfB = pd.read_csv(\"channel_width_test.csv\")\n",
    "gdfB = gpd.GeoDataFrame(\n",
    "    dfB, geometry=gpd.points_from_xy(dfB.easting, dfB.northing))\n",
    "# We have to tell the geopandas data what geographic system we are in by using something called an EPSG code. \n",
    "# All major geographic projection and transformation system have this code. \n",
    "gdfB.crs = \"EPSG:27700\" \n",
    "\n",
    "# IMPORTANT: we convert one of the datasets to the coordinate reference system of the other\n",
    "gdfC = gdfB.to_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbf8b9",
   "metadata": {},
   "source": [
    "The next three lines just show what the first few lines of data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48af7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78317314",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1660f69",
   "metadata": {},
   "source": [
    "## Add the function for combining datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e4e75",
   "metadata": {},
   "source": [
    "The below function merges two datasets using nearest neighbours. \n",
    "**You don't need to change anything in this function.**\n",
    "The first dataframe keeps its data elements and adds properties from the nearest neighbour that are closest to the points in the first dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a993bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckdnearest(gdA, gdB):\n",
    "\n",
    "    nA = np.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k=1)\n",
    "    gdB_nearest = gdB.iloc[idx].drop(columns=\"geometry\").reset_index(drop=True)\n",
    "    gdf = pd.concat(\n",
    "        [\n",
    "            gdA.reset_index(drop=True),\n",
    "            gdB_nearest,\n",
    "            pd.Series(dist, name='dist')\n",
    "        ], \n",
    "        axis=1)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6fa1d",
   "metadata": {},
   "source": [
    "## Merge the two files!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890a7e5",
   "metadata": {},
   "source": [
    "Now we merge the channel widths, that have been converted to the correct coordinate reference system, with the channel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4890fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdp = ckdnearest(gdfC, gdfA)\n",
    "new_gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90624c69",
   "metadata": {},
   "source": [
    "Super! Now we can print this new dataset to a file using the `.to_csv` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gdp.to_csv(\"updated_channel_width.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3036b8",
   "metadata": {},
   "source": [
    "Okay, lets load this new csv file to see if it has the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab42e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv(\"updated_channel_width.csv\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f0563f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
